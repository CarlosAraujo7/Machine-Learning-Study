{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curso de Machine Learning - Udemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import networkx as nx\n",
    "import yellowbrick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base de dados de crédito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fonte (adatpada): https://www.kaggle.com/laotse/credit-risk-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit = pd.read_csv('Bases de dados/credit_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importando a base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Executando a base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pegandos os primeiros registros da base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clientid</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>loan</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1996</td>\n",
       "      <td>59221.044874</td>\n",
       "      <td>48.518179</td>\n",
       "      <td>1926.729397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1997</td>\n",
       "      <td>69516.127573</td>\n",
       "      <td>23.162104</td>\n",
       "      <td>3503.176156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1998</td>\n",
       "      <td>44311.449262</td>\n",
       "      <td>28.017167</td>\n",
       "      <td>5522.786693</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1999</td>\n",
       "      <td>43756.056605</td>\n",
       "      <td>63.971796</td>\n",
       "      <td>1622.722598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2000</td>\n",
       "      <td>69436.579552</td>\n",
       "      <td>56.152617</td>\n",
       "      <td>7378.833599</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      clientid        income        age         loan  default\n",
       "1995      1996  59221.044874  48.518179  1926.729397        0\n",
       "1996      1997  69516.127573  23.162104  3503.176156        0\n",
       "1997      1998  44311.449262  28.017167  5522.786693        1\n",
       "1998      1999  43756.056605  63.971796  1622.722598        0\n",
       "1999      2000  69436.579552  56.152617  7378.833599        0"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_credit.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pegandos os últimos registros da base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Retorna uma descrição em forma de contagem do elementos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(base_credit['default'], return_counts = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `unique` retorna os valores únicos de uma coluna;\n",
    "- `return_counts = True` retorna a quantidade dos valores que se encaixam no unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = base_credit['default']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gera um gráfico de barra para os valores pedidos;\n",
    "- O \";\" limpa a saída de textos poluídos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x =  base_credit['age']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gera um histograma dos valores pedidos, nesse exemplo, um histograma com as idades na base de cŕedito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico = px.scatter_matrix(base_credit, dimensions = ['age', 'income', 'loan'], color = 'default')\n",
    "grafico.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gera um gráfico interativo de acordo com os parâmetros inseridos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de valores inconsistentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit.loc[base_credit['age'] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Olhando as idades inválidas (abaixo de zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pegando a média dos valores da base de cŕedito, porém dessa forma, todos os valores estão tendo suas médias inclusas e só queremos as médias de idades para preencher os valores inválidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit['age'][base_credit['age'] > 0].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Forma correta de pegar a média sem considerar as idades inválidas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Forma errada de alterar os dados inválidos pela média\n",
    "\n",
    "   **base_credit.loc[base_credit['age'] < 0] = 40.92**\n",
    "\n",
    "- Dessa forma, a linha inteira vai ser alterada para o valor inserido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit.loc[base_credit['age'] < 0, 'age'] = 40.92"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Forma correta de alterar dados inválidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamentos de valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Forma de olhar os valores faltantes, se for 0 é válido, se for 1, então existe algum valor faltante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit.loc[pd.isnull(base_credit['age'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Forma de localizar os valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit['age'].fillna(base_credit['age'].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Forma de preencher os valores nulos com a média das idades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit.loc[(base_credit['clientid'].isin([29, 31, 32]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Forma simples de localizar os elementos em um intervalo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão entre previsores e classe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No aprendizado de máquina supervisionado, os dados de entrada podem ser divididos em dois grupos\n",
    "- X: são os atributos que vão ser utilizados para determinar a classe de saída. Esses atributos também podem ser chamados de previsores.\n",
    "- Y: é o atributo para o qual se deseja fazer a predição do valor de saída (também chamado de atributo-alvo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_credit = base_credit.iloc[:, 1:4].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pegando os valores e as colunas especificadas nesse intervalo e colocando-os na variável `X`, nesse caso, `X_credit`.\n",
    "- `values` é usado para converter os dados para um formato melhor de se trabalhar pelo computador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mostrando os valores que estão atualmente na variável `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_credit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mostrando o tipo atual desse formato de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_credit = base_credit.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fazendo a atribuição da classe ou atributo-alvo em `Y`, nesse caso, `Y_credit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mostrando os valores que estão atualmente na variável `Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Y_credit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mostrando o tipo atual desse formato de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escalonamento de valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os algoritmos de aprendizado de máquina tendem a favorecer os dados de tamanhos maiores e deixar de lado os dados com valores menores, atribuindo maior peso e importância para os dados com valores maiores.\n",
    "\n",
    "Quase nunca isso é uma coisa boa, por isso, temos técnicas que ajudam a equalizar melhor os pesos que cada dado deve ter.\n",
    "\n",
    "Os seguintes cálculos ajudam nesse problema: \n",
    "\n",
    "**Padronização** (Standardisation)\n",
    "\n",
    "$x = \\dfrac{x - média(x)}{desviopadrão(x)}$\n",
    "\n",
    "**Normalização** (Normalization)\n",
    "\n",
    "$x = \\dfrac{x - mínimo(x)}{máximo(x) - mínimo(x)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_credit = StandardScaler()\n",
    "X_credit = scaler_credit.fit_transform(X_credit)\n",
    "\n",
    "X_credit[:,0].min(), X_credit[:,1].min(), X_credit[:,2].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A partir da biblioteca Sklearn, importamos a função que vai padronizar nossos dados\n",
    "- Pegamos os menores valores de cada coluna (atributo) da nossa base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Podemos ver que agora dos dados da nossa base estão na mesma escala.\n",
    "- Dizemos que esses dados estão escalonados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base de dados do censo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fonte: http://archive.ics.uci.edu/ml/datasets/adult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esploração dos dados \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_census = pd.read_csv('Bases de dados/census.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_census.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a função `describe` podemos ver um quado geral dos dados da nossa base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_census.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando `isnull` e `sum` podemos verificar se temos dados faltantes e/ou negativos, o que não é o caso para essa base de dados do census"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(base_census['income'], return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Usando a chamada acima, podemos pegar os valores referentes ao atributo `income (renda)` e a quantidade de dados que atendem a esses valores  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = base_census['income']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Podemos considerar esses tipos de dados como `desbalanceados` por termos uma quantidade muito maior de um tipo de dado em relação ao outro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x = base_census['age']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x = base_census['education-num']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x = base_census['hour-per-week']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico = px.treemap(base_census, path = ['workclass', 'age', 'income']);\n",
    "grafico.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Como mostrado acima, a função `treemap` mostra as hierarquias dos dados usando vários quadrados aninhados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico = px.parallel_categories(base_census, dimensions = ['occupation', 'relationship']);\n",
    "grafico.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A função `parallel_categories` consegue relacionar os dados de dois atributos distintos e mostrar isso em um gráfico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão entre previsores e classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_census.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_census = base_census.iloc[:, 0:14].values\n",
    "X_census"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A função `iloc` é uma função do `pandas` usada para selecionar dados com base em sua posição numérica.\n",
    "- `dataframe.iloc[linhas, colunas]`\n",
    "\n",
    "- No caso, `X_census` está pegando todas as linhas e até a coluna 13, sem pegar a coluna 14 que é a `renda (income)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_census = base_census.iloc[:, 14].values\n",
    "Y_census"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de atributos categóricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A função `fit_transform` ajusta o modelo de treinamento e em seguida aplica uma transformaçãono modelo\n",
    "- A função `LabelEncoder` transforma `rótulos (dados categóricos)` em dados numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_census[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_teste = LabelEncoder()\n",
    "label_encoder_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = label_encoder_teste.fit_transform(X_census[:, 1])\n",
    "teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_census[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_workclass = LabelEncoder()\n",
    "label_encoder_education = LabelEncoder()\n",
    "label_encoder_marital = LabelEncoder()\n",
    "label_encoder_occupation = LabelEncoder()\n",
    "label_encoder_relationship = LabelEncoder()\n",
    "label_encoder_race = LabelEncoder()\n",
    "label_encoder_sex = LabelEncoder()\n",
    "label_encoder_country = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_census[:, 1] = label_encoder_workclass.fit_transform(X_census[:, 1])\n",
    "X_census[:, 3] = label_encoder_education.fit_transform(X_census[:, 3])\n",
    "X_census[:, 5] = label_encoder_marital.fit_transform(X_census[:, 5])\n",
    "X_census[:, 6] = label_encoder_occupation.fit_transform(X_census[:, 6])\n",
    "X_census[:, 7] = label_encoder_relationship.fit_transform(X_census[:, 7])\n",
    "X_census[:, 8] = label_encoder_race.fit_transform(X_census[:, 8])\n",
    "X_census[:, 9] = label_encoder_sex.fit_transform(X_census[:, 9])\n",
    "X_census[:, 13] = label_encoder_country.fit_transform(X_census[:, 13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_census[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(base_census['workclass']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneHotEncoder_census = ColumnTransformer(transformers=[('OneHot', OneHotEncoder(), [1, 3, 5, 6, 7, 8, 9, 13])], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_census = OneHotEncoder_census.fit_transform(X_census).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_census.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Escalonamento dos valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_census = StandardScaler()\n",
    "X_census = scaler_census.fit_transform(X_census)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_census"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão das bases em treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_credit_treinamento, X_credit_teste, Y_credit_treinamento, Y_credit_teste = train_test_split(X_credit, Y_credit, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_census_treinamento, X_census_teste, Y_census_treinamento, Y_census_teste = train_test_split(X_census, Y_census, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvar as variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('credit.pkl', mode='wb') as f:\n",
    "    pickle.dump([X_credit_treinamento, Y_credit_treinamento, X_credit_teste, Y_credit_teste], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('census.pkl', mode='wb') as f:\n",
    "    pickle.dump([X_census_treinamento, Y_census_treinamento, X_census_teste, Y_census_teste], f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizagem Bayesiana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes (extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- O algoritmo ``Naive Bayes`` é um classificador probabilístico que assume que as ``características (features)`` são independentes entre si, daí o termo ``“naive” (ingênuo)``. Essa é uma simplificação feita para facilitar o cálculo das probabilidades condicionais necessárias para classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(A|B) = \\dfrac{P(B|A) \\ P(A)}{P(B)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Na prática, o algoritmo Naive Bayes é frequentemente utilizado para classificar textos, como na detecção de spam ou na categorização de documentos. Ele usa a frequência das palavras para calcular a probabilidade de um documento pertencer a uma determinada classe (por exemplo, spam ou não spam).\n",
    "\n",
    "- Embora o algoritmo Naive Bayes seja simples e rápido, nem sempre é o classificador mais preciso, principalmente quando as características são altamente correlacionadas. No entanto, em muitos casos, o Naive Bayes pode fornecer resultados satisfatórios com um pequeno número de dados de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Criando o dataframe de exemplo\n",
    "dados = {\n",
    "    'temperatura': [30, 25, 28, 18, 20, 22, 24, 28, 26, 30],\n",
    "    'umidade': [85, 90, 78, 65, 75, 70, 80, 75, 80, 70],\n",
    "    'jogar_tenis': ['Não', 'Não', 'Sim', 'Sim', 'Sim', 'Sim', 'Não', 'Sim', 'Sim', 'Não']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(dados)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Separando as variáveis de entrada (temperatura e umidade) e o alvo (jogar_tenis)\n",
    "X = df[['temperatura', 'umidade']]\n",
    "y = df['jogar_tenis']\n",
    "\n",
    "# Dividindo o conjunto de dados em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42)\n",
    "\n",
    "# Criando o modelo Naive Bayes Gaussiano\n",
    "modelo = GaussianNB()\n",
    "\n",
    "# Treinando o modelo\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo previsões\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "# Calculando a acurácia do modelo\n",
    "acuracia = accuracy_score(y_test, y_pred)\n",
    "print(f'Acurácia: {acuracia * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O ``test_size`` é um parâmetro que determina a proporção do conjunto de dados que será reservada para o conjunto de teste. Por exemplo, se test_size for definido como 0.2, isso significa que 20% dos dados serão usados como conjunto de teste, enquanto os 80% restantes serão usados como conjunto de treinamento. A escolha adequada do tamanho do conjunto de teste é importante para avaliar adequadamente o desempenho do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O ``random_state`` é um parâmetro opcional que permite que você fixe a semente (seed) usada pelo gerador de números aleatórios durante a divisão dos dados. Fixar a semente garante reprodutibilidade, ou seja, se você usar a mesma semente, obterá a mesma divisão de dados em diferentes execuções do código. Isso é útil para garantir resultados consistentes ao compartilhar código ou ao tentar depurar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes (exemplos do curso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base risco de crédito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_risco_credito = pd.read_csv('Bases de dados/risco_credito.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_risco_credito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_risco_credito = base_risco_credito.iloc[:, 0:4].values\n",
    "X_risco_credito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_risco_credito = base_risco_credito.iloc[:, 4:5].values\n",
    "Y_risco_credito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_historia = LabelEncoder()\n",
    "label_encoder_divida = LabelEncoder()\n",
    "label_encoder_garantias = LabelEncoder()\n",
    "label_encoder_renda = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_risco_credito[:, 0] = label_encoder_historia.fit_transform(X_risco_credito[:, 0])\n",
    "X_risco_credito[:, 1] = label_encoder_divida.fit_transform(X_risco_credito[:, 1])\n",
    "X_risco_credito[:, 2] = label_encoder_garantias.fit_transform(X_risco_credito[:, 2])\n",
    "X_risco_credito[:, 3] = label_encoder_renda.fit_transform(X_risco_credito[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_risco_credito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('risco_credito.pkl', 'wb') as f:\n",
    "    pickle.dump([X_risco_credito, Y_risco_credito], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_risco_credito = GaussianNB()\n",
    "naive_risco_credito.fit(X_risco_credito, Y_risco_credito)                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsao = naive_risco_credito.predict([[0, 0, 1, 2], [2, 0, 0, 0]])\n",
    "previsao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_risco_credito.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_risco_credito.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_risco_credito.class_prior_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base credit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('credit.pkl', 'rb') as f:\n",
    "    X_credit_treinamento, Y_credit_treinamento, X_credit_teste, Y_credit_teste = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_credit_treinamento.shape, Y_credit_treinamento.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_credit_teste.shape, Y_credit_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_credit_data = GaussianNB()\n",
    "naive_credit_data.fit(X_credit_treinamento, Y_credit_treinamento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nos comandos acima, nós instânciamos o algoritmo de Naive Bayes com o método de Gauss.\n",
    "- O comando `fit` faz o treinamento do algoritmo usando os parâmetros escolhidos e gera uma ``tabela de probabilidade``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Com o algoritmo treinado, podemos usar o comando `predict` para fazer previsões de dados na nova base de dados\n",
    "- Lembrando que os dados que serão usados para as previsões são os dados de ``teste`` e não os dados de `treinamento` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = naive_credit_data.predict(X_credit_teste)\n",
    "previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(Y_credit_teste, previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_credit_teste, previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_credit_teste, previsoes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('census.pkl', 'rb') as f:\n",
    "    X_census_treinamento, Y_census_treinamento, X_census_teste, Y_census_teste = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_census_treinamento.shape, Y_census_treinamento.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_census_data = GaussianNB()\n",
    "naive_census_data.fit(X_census_treinamento, Y_census_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_prev = naive_census_data.predict(X_census_teste)\n",
    "census_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(Y_census_teste, census_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_census_teste, census_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_census_teste, census_prev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfusionMatrix(naive_census_data)\n",
    "cm.fit(X_census_treinamento, Y_census_treinamento)\n",
    "cm.score(X_census_teste, Y_census_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizagem por Árvores de Decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para gerarmos a árvore de decisão temos duas fórmulas que podem ser aplicadas: \n",
    "- Entropy (entropia)\n",
    "\n",
    "    $Entropy(S) = \\displaystyle\\sum_{i=1}^{c}$ - $pi \\cdot \\log_2pi $\n",
    "\n",
    "- Gain (ganho de informação)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após gerarmos uma árvore de decisão, podemos aplicar modificações que chamamos de ``poda (podar uma ávore)`\n",
    "- **Bias (viés)**\n",
    "\n",
    "    * Erros por classificação errada\n",
    "\n",
    "- **Variância**\n",
    "\n",
    "    * Erros por sensibilidade pequena à mudanças na base de dados de treinamneto\n",
    "\n",
    "    * Pode levar a ``Overfitting`` (quando o algoritmo se adapta demais a base de treinamento e quando vai para a base de teste comete muitos erros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Vantagens**\n",
    "    \n",
    "    * Fácil interpretação\n",
    "\n",
    "    * Não precisa de normalização ou padronização\n",
    "\n",
    "    * Rápido para classificar novo registros\n",
    "\n",
    "- **Desvantagens**\n",
    "\n",
    "    * Geração de árvores muito complexas\n",
    "\n",
    "    * Pequenas mudanças nos dados podem mudar a árvore (podar pode ajudar)\n",
    "\n",
    "    * Problema ``NP-Completo`` para construir a árvore\n",
    "\n",
    "- Era um método muito popular em meados dos anos 90\n",
    "\n",
    "- Upgrades como ``random forest (florestas randômicas)`` melhoram o desempenho (usado no Kinect da microsoft)\n",
    "\n",
    "- CART - Classification and Regression Tress (Ávores para Classficação e Regressão)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árvores de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base risco de crédito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('risco_credito.pkl', 'rb') as f:\n",
    "    X_risco_credito, Y_risco_credito = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arvore_risco_credito = DecisionTreeClassifier(criterion='entropy')\n",
    "arvore_risco_credito.fit(X_risco_credito, Y_risco_credito)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arvore_risco_credito.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "tree.plot_tree(arvore_risco_credito)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "previsores = ['história', 'dívida', 'garantias', 'renda']\n",
    "tree.plot_tree(arvore_risco_credito, feature_names=previsores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "previsores = ['história', 'dívida', 'garantias', 'renda']\n",
    "figura, eixos = plt.subplots(nrows=1, ncols=1, figsize=(10, 10))\n",
    "tree.plot_tree(arvore_risco_credito, feature_names=previsores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arvore_risco_credito.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "previsores = ['história', 'dívida', 'garantias', 'renda']\n",
    "figura, eixos = plt.subplots(nrows=1, ncols=1, figsize=(10, 10))\n",
    "tree.plot_tree(arvore_risco_credito, feature_names=previsores, class_names = arvore_risco_credito.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "previsores = ['história', 'dívida', 'garantias', 'renda']\n",
    "figura, eixos = plt.subplots(nrows=1, ncols=1, figsize=(10, 10))\n",
    "tree.plot_tree(arvore_risco_credito, feature_names=previsores, class_names = arvore_risco_credito.classes_, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "previsores = ['história', 'dívida', 'garantias', 'renda']\n",
    "figura, eixos = plt.subplots(nrows=1, ncols=1, figsize=(10, 10))\n",
    "tree.plot_tree(arvore_risco_credito, feature_names=previsores, class_names = arvore_risco_credito.classes_, filled=True); # o ; remove os textos redundantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# história boa, dívida alta, garantias nenhuma, renda > 35\n",
    "# história ruim, dívida alta, garantias adequada, renda < 15\n",
    "\n",
    "previsoes = arvore_risco_credito.predict([[0, 0, 1, 2], [2, 0, 0, 0]])\n",
    "previsoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base credit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('credit.pkl', 'rb') as f:\n",
    "    X_credit_treinamento, Y_credit_treinamento, X_credit_teste, Y_credit_teste = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arvore_credit = DecisionTreeClassifier(criterion='entropy', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arvore_credit.fit(X_credit_treinamento, Y_credit_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = arvore_credit.predict(X_credit_teste)\n",
    "previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_credit_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "accuracy = accuracy_score(Y_credit_teste, previsoes)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "cm = ConfusionMatrix(arvore_credit)\n",
    "cm.fit(X_credit_treinamento, Y_credit_treinamento)\n",
    "cm.score(X_credit_teste, Y_credit_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_credit_teste, previsoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arvore_credit.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(arvore_credit.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "previsores = ['income', 'age', 'loan']\n",
    "\n",
    "# Converta as classes para uma lista\n",
    "class_names_list = [str(classe) for classe in arvore_credit.classes_]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(20, 20))\n",
    "tree.plot_tree(arvore_credit, feature_names=previsores, class_names=class_names_list, filled=True)\n",
    "\n",
    "fig.savefig('arvore_credit.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "previsores = ['income', 'age', 'loan']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(20, 20))\n",
    "tree.plot_tree(arvore_credit, feature_names=previsores, class_names=['0', '1'], filled=True)\n",
    "\n",
    "fig.savefig('arvore_credit2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base census"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
