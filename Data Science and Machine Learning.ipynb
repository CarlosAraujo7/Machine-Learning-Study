{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curso de Machine Learning - Udemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas\n",
    "# %pip install seaborn\n",
    "# %pip install plotly\n",
    "# %pip install networkx\n",
    "# %pip install yellowbrick\n",
    "# %pip install pyarrow\n",
    "# %pip install numpy==1.24.0\n",
    "# %pip install nbformat\n",
    "# %pip install --upgrade jupyter\n",
    "# %pip install orange3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import seaborn\n",
    "import matplotlib.pyplot\n",
    "import plotly.express\n",
    "import networkx\n",
    "import yellowbrick\n",
    "import Orange\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base de dados de crédito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fonte (adatpada): https://www.kaggle.com/laotse/credit-risk-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit = pandas.read_csv('Bases de dados/credit_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importando a base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Executando a base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pegandos os primeiros registros da base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pegandos os últimos registros da base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Retorna uma descrição em forma de contagem do elementos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.unique(base_credit['default'], return_counts = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `unique` retorna os valores únicos de uma coluna;\n",
    "- `return_counts = True` retorna a quantidade dos valores que se encaixam no unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.countplot(x = base_credit['default']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gera um gráfico de barra para os valores pedidos;\n",
    "- O \";\" limpa a saída de textos poluídos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.hist(x =  base_credit['age']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gera um histograma dos valores pedidos, nesse exemplo, um histograma com as idades na base de cŕedito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico = plotly.express.scatter_matrix(base_credit, dimensions = ['age', 'income', 'loan'], color = 'default')\n",
    "grafico.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gera um gráfico interativo de acordo com os parâmetros inseridos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de valores inconsistentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit.loc[base_credit['age'] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Olhando as idades inválidas (abaixo de zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pegando a média dos valores da base de cŕedito, porém dessa forma, todos os valores estão tendo suas médias inclusas e só queremos as médias de idades para preencher os valores inválidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit['age'][base_credit['age'] > 0].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Forma correta de pegar a média sem considerar as idades inválidas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Forma errada de alterar os dados inválidos pela média\n",
    "\n",
    "   **base_credit.loc[base_credit['age'] < 0] = 40.92**\n",
    "\n",
    "- Dessa forma, a linha inteira vai ser alterada para o valor inserido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit.loc[base_credit['age'] < 0, 'age'] = 40.92"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Forma correta de alterar dados inválidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamentos de valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Forma de olhar os valores faltantes, se for 0 é válido, se for 1, então existe algum valor faltante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit.loc[pandas.isnull(base_credit['age'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Forma de localizar os valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit['age'].fillna(base_credit['age'].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Forma de preencher os valores nulos com a média das idades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit.loc[(base_credit['clientid'].isin([29, 31, 32]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Forma simples de localizar os elementos em um intervalo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão entre previsores e classe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No aprendizado de máquina supervisionado, os dados de entrada podem ser divididos em dois grupos\n",
    "- X: são os atributos que vão ser utilizados para determinar a classe de saída. Esses atributos também podem ser chamados de previsores.\n",
    "- Y: é o atributo para o qual se deseja fazer a predição do valor de saída (também chamado de atributo-alvo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_credit = base_credit.iloc[:, 1:4].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pegando os valores e as colunas especificadas nesse intervalo e colocando-os na variável `X`, nesse caso, `X_credit`.\n",
    "- `values` é usado para converter os dados para um formato melhor de se trabalhar pelo computador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mostrando os valores que estão atualmente na variável `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_credit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mostrando o tipo atual desse formato de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_credit = base_credit.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fazendo a atribuição da classe ou atributo-alvo em `Y`, nesse caso, `Y_credit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mostrando os valores que estão atualmente na variável `Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Y_credit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mostrando o tipo atual desse formato de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escalonamento de valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os algoritmos de aprendizado de máquina tendem a favorecer os dados de tamanhos maiores e deixar de lado os dados com valores menores, atribuindo maior peso e importância para os dados com valores maiores.\n",
    "\n",
    "Quase nunca isso é uma coisa boa, por isso, temos técnicas que ajudam a equalizar melhor os pesos que cada dado deve ter.\n",
    "\n",
    "Os seguintes cálculos ajudam nesse problema: \n",
    "\n",
    "**Padronização** (Standardisation)\n",
    "\n",
    "$x = \\dfrac{x - média(x)}{desviopadrão(x)}$\n",
    "\n",
    "**Normalização** (Normalization)\n",
    "\n",
    "$x = \\dfrac{x - mínimo(x)}{máximo(x) - mínimo(x)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_credit = StandardScaler()\n",
    "X_credit = scaler_credit.fit_transform(X_credit)\n",
    "\n",
    "X_credit[:,0].min(), X_credit[:,1].min(), X_credit[:,2].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A partir da biblioteca Sklearn, importamos a função que vai padronizar nossos dados\n",
    "- Pegamos os menores valores de cada coluna (atributo) da nossa base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Podemos ver que agora dos dados da nossa base estão na mesma escala.\n",
    "- Dizemos que esses dados estão escalonados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base de dados do censo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fonte: http://archive.ics.uci.edu/ml/datasets/adult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esploração dos dados \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_census = pandas.read_csv('Bases de dados/census.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_census.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a função `describe` podemos ver um quado geral dos dados da nossa base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_census.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando `isnull` e `sum` podemos verificar se temos dados faltantes e/ou negativos, o que não é o caso para essa base de dados do census"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.unique(base_census['income'], return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Usando a chamada acima, podemos pegar os valores referentes ao atributo `income (renda)` e a quantidade de dados que atendem a esses valores  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.countplot(x = base_census['income']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Podemos considerar esses tipos de dados como `desbalanceados` por termos uma quantidade muito maior de um tipo de dado em relação ao outro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.hist(x = base_census['age']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.hist(x = base_census['education-num']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.hist(x = base_census['hour-per-week']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico = plotly.express.treemap(base_census, path = ['workclass', 'age', 'income']);\n",
    "grafico.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Como mostrado acima, a função `treemap` mostra as hierarquias dos dados usando vários quadrados aninhados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico = plotly.express.parallel_categories(base_census, dimensions = ['occupation', 'relationship']);\n",
    "grafico.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A função `parallel_categories` consegue relacionar os dados de dois atributos distintos e mostrar isso em um gráfico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão entre previsores e classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_census.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_census = base_census.iloc[:, 0:14].values\n",
    "X_census"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A função `iloc` é uma função do `pandas` usada para selecionar dados com base em sua posição numérica.\n",
    "- `dataframe.iloc[linhas, colunas]`\n",
    "\n",
    "- No caso, `X_census` está pegando todas as linhas e até a coluna 13, sem pegar a coluna 14 que é a `renda (income)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_census = base_census.iloc[:, 14].values\n",
    "Y_census"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de atributos categóricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A função `fit_transform` ajusta o modelo de treinamento e em seguida aplica uma transformaçãono modelo\n",
    "- A função `LabelEncoder` transforma `rótulos (dados categóricos)` em dados numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_census[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_teste = LabelEncoder()\n",
    "label_encoder_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = label_encoder_teste.fit_transform(X_census[:, 1])\n",
    "teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_census[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_workclass = LabelEncoder()\n",
    "label_encoder_education = LabelEncoder()\n",
    "label_encoder_marital = LabelEncoder()\n",
    "label_encoder_occupation = LabelEncoder()\n",
    "label_encoder_relationship = LabelEncoder()\n",
    "label_encoder_race = LabelEncoder()\n",
    "label_encoder_sex = LabelEncoder()\n",
    "label_encoder_country = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_census[:, 1] = label_encoder_workclass.fit_transform(X_census[:, 1])\n",
    "X_census[:, 3] = label_encoder_education.fit_transform(X_census[:, 3])\n",
    "X_census[:, 5] = label_encoder_marital.fit_transform(X_census[:, 5])\n",
    "X_census[:, 6] = label_encoder_occupation.fit_transform(X_census[:, 6])\n",
    "X_census[:, 7] = label_encoder_relationship.fit_transform(X_census[:, 7])\n",
    "X_census[:, 8] = label_encoder_race.fit_transform(X_census[:, 8])\n",
    "X_census[:, 9] = label_encoder_sex.fit_transform(X_census[:, 9])\n",
    "X_census[:, 13] = label_encoder_country.fit_transform(X_census[:, 13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_census[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(numpy.unique(base_census['workclass']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneHotEncoder_census = ColumnTransformer(transformers=[('OneHot', OneHotEncoder(), [1, 3, 5, 6, 7, 8, 9, 13])], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_census = OneHotEncoder_census.fit_transform(X_census).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_census.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Escalonamento dos valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_census = StandardScaler()\n",
    "X_census = scaler_census.fit_transform(X_census)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_census"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão das bases em treinamento e teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_credit_treinamento, X_credit_teste, Y_credit_treinamento, Y_credit_teste = train_test_split(X_credit, Y_credit, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_census_treinamento, X_census_teste, Y_census_treinamento, Y_census_teste = train_test_split(X_census, Y_census, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvar as variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('credit.pkl', mode='wb') as f:\n",
    "    pickle.dump([X_credit_treinamento, Y_credit_treinamento, X_credit_teste, Y_credit_teste], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('census.pkl', mode='wb') as f:\n",
    "    pickle.dump([X_census_treinamento, Y_census_treinamento, X_census_teste, Y_census_teste], f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizagem Bayesiana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes (extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- O algoritmo ``Naive Bayes`` é um classificador probabilístico que assume que as ``características (features)`` são independentes entre si, daí o termo ``“naive” (ingênuo)``. Essa é uma simplificação feita para facilitar o cálculo das probabilidades condicionais necessárias para classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(A|B) = \\dfrac{P(B|A) \\ P(A)}{P(B)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Na prática, o algoritmo Naive Bayes é frequentemente utilizado para classificar textos, como na detecção de spam ou na categorização de documentos. Ele usa a frequência das palavras para calcular a probabilidade de um documento pertencer a uma determinada classe (por exemplo, spam ou não spam).\n",
    "\n",
    "- Embora o algoritmo Naive Bayes seja simples e rápido, nem sempre é o classificador mais preciso, principalmente quando as características são altamente correlacionadas. No entanto, em muitos casos, o Naive Bayes pode fornecer resultados satisfatórios com um pequeno número de dados de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o dataframe de exemplo\n",
    "dados = {\n",
    "    'temperatura': [30, 25, 28, 18, 20, 22, 24, 28, 26, 30],\n",
    "    'umidade': [85, 90, 78, 65, 75, 70, 80, 75, 80, 70],\n",
    "    'jogar_tenis': ['Não', 'Não', 'Sim', 'Sim', 'Sim', 'Sim', 'Não', 'Sim', 'Sim', 'Não']\n",
    "}\n",
    "\n",
    "df = pandas.DataFrame(dados)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as variáveis de entrada (temperatura e umidade) e o alvo (jogar_tenis)\n",
    "X = df[['temperatura', 'umidade']]\n",
    "y = df['jogar_tenis']\n",
    "\n",
    "# Dividindo o conjunto de dados em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42)\n",
    "\n",
    "# Criando o modelo Naive Bayes Gaussiano\n",
    "modelo = GaussianNB()\n",
    "\n",
    "# Treinando o modelo\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo previsões\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "# Calculando a acurácia do modelo\n",
    "acuracia = accuracy_score(y_test, y_pred)\n",
    "print(f'Acurácia: {acuracia * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O ``test_size`` é um parâmetro que determina a proporção do conjunto de dados que será reservada para o conjunto de teste. Por exemplo, se test_size for definido como 0.2, isso significa que 20% dos dados serão usados como conjunto de teste, enquanto os 80% restantes serão usados como conjunto de treinamento. A escolha adequada do tamanho do conjunto de teste é importante para avaliar adequadamente o desempenho do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O ``random_state`` é um parâmetro opcional que permite que você fixe a semente (seed) usada pelo gerador de números aleatórios durante a divisão dos dados. Fixar a semente garante reprodutibilidade, ou seja, se você usar a mesma semente, obterá a mesma divisão de dados em diferentes execuções do código. Isso é útil para garantir resultados consistentes ao compartilhar código ou ao tentar depurar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes (exemplos do curso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base risco de crédito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_risco_credito = pandas.read_csv('Bases de dados/risco_credito.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_risco_credito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_risco_credito = base_risco_credito.iloc[:, 0:4].values\n",
    "X_risco_credito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_risco_credito = base_risco_credito.iloc[:, 4:5].values\n",
    "Y_risco_credito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_historia = LabelEncoder()\n",
    "label_encoder_divida = LabelEncoder()\n",
    "label_encoder_garantias = LabelEncoder()\n",
    "label_encoder_renda = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_risco_credito[:, 0] = label_encoder_historia.fit_transform(X_risco_credito[:, 0])\n",
    "X_risco_credito[:, 1] = label_encoder_divida.fit_transform(X_risco_credito[:, 1])\n",
    "X_risco_credito[:, 2] = label_encoder_garantias.fit_transform(X_risco_credito[:, 2])\n",
    "X_risco_credito[:, 3] = label_encoder_renda.fit_transform(X_risco_credito[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_risco_credito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('risco_credito.pkl', 'wb') as f:\n",
    "    pickle.dump([X_risco_credito, Y_risco_credito], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_risco_credito = GaussianNB()\n",
    "naive_risco_credito.fit(X_risco_credito, Y_risco_credito)                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsao = naive_risco_credito.predict([[0, 0, 1, 2], [2, 0, 0, 0]])\n",
    "previsao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_risco_credito.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_risco_credito.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_risco_credito.class_prior_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base credit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('credit.pkl', 'rb') as f:\n",
    "    X_credit_treinamento, Y_credit_treinamento, X_credit_teste, Y_credit_teste = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_credit_treinamento.shape, Y_credit_treinamento.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_credit_teste.shape, Y_credit_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_credit_data = GaussianNB()\n",
    "naive_credit_data.fit(X_credit_treinamento, Y_credit_treinamento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nos comandos acima, nós instânciamos o algoritmo de Naive Bayes com o método de Gauss.\n",
    "- O comando `fit` faz o treinamento do algoritmo usando os parâmetros escolhidos e gera uma ``tabela de probabilidade``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Com o algoritmo treinado, podemos usar o comando `predict` para fazer previsões de dados na nova base de dados\n",
    "- Lembrando que os dados que serão usados para as previsões são os dados de ``teste`` e não os dados de `treinamento` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = naive_credit_data.predict(X_credit_teste)\n",
    "previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(Y_credit_teste, previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_credit_teste, previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_credit_teste, previsoes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('census.pkl', 'rb') as f:\n",
    "    X_census_treinamento, Y_census_treinamento, X_census_teste, Y_census_teste = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_census_treinamento.shape, Y_census_treinamento.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_census_data = GaussianNB()\n",
    "naive_census_data.fit(X_census_treinamento, Y_census_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_prev = naive_census_data.predict(X_census_teste)\n",
    "census_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(Y_census_teste, census_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_census_teste, census_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_census_teste, census_prev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfusionMatrix(naive_census_data)\n",
    "cm.fit(X_census_treinamento, Y_census_treinamento)\n",
    "cm.score(X_census_teste, Y_census_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizagem por Árvores de Decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para gerarmos a árvore de decisão temos duas fórmulas que podem ser aplicadas: \n",
    "- Entropy (entropia)\n",
    "\n",
    "    $Entropy(S) = \\displaystyle\\sum_{i=1}^{c}$ - $pi \\cdot \\log_2pi $\n",
    "\n",
    "- Gain (ganho de informação)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após gerarmos uma árvore de decisão, podemos aplicar modificações que chamamos de ``poda (podar uma ávore)`\n",
    "- **Bias (viés)**\n",
    "\n",
    "    * Erros por classificação errada\n",
    "\n",
    "- **Variância**\n",
    "\n",
    "    * Erros por sensibilidade pequena à mudanças na base de dados de treinamneto\n",
    "\n",
    "    * Pode levar a ``Overfitting`` (quando o algoritmo se adapta demais a base de treinamento e quando vai para a base de teste comete muitos erros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Vantagens**\n",
    "    \n",
    "    * Fácil interpretação\n",
    "\n",
    "    * Não precisa de normalização ou padronização\n",
    "\n",
    "    * Rápido para classificar novo registros\n",
    "\n",
    "- **Desvantagens**\n",
    "\n",
    "    * Geração de árvores muito complexas\n",
    "\n",
    "    * Pequenas mudanças nos dados podem mudar a árvore (podar pode ajudar)\n",
    "\n",
    "    * Problema ``NP-Completo`` para construir a árvore\n",
    "\n",
    "- Era um método muito popular em meados dos anos 90\n",
    "\n",
    "- Upgrades como ``random forest (florestas randômicas)`` melhoram o desempenho (usado no Kinect da microsoft)\n",
    "\n",
    "- CART - Classification and Regression Tress (Ávores para Classficação e Regressão)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árvores de decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base risco de crédito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('risco_credito.pkl', 'rb') as f:\n",
    "    X_risco_credito, Y_risco_credito = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arvore_risco_credito = DecisionTreeClassifier(criterion='entropy')\n",
    "arvore_risco_credito.fit(X_risco_credito, Y_risco_credito)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arvore_risco_credito.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.plot_tree(arvore_risco_credito)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = ['história', 'dívida', 'garantias', 'renda']\n",
    "\n",
    "tree.plot_tree(arvore_risco_credito, feature_names=previsores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = ['história', 'dívida', 'garantias', 'renda']\n",
    "\n",
    "figura, eixos = matplotlib.pyplot.subplots(nrows=1, ncols=1, figsize=(10, 10))\n",
    "\n",
    "tree.plot_tree(arvore_risco_credito, feature_names=previsores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arvore_risco_credito.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = ['história', 'dívida', 'garantias', 'renda']\n",
    "\n",
    "figura, eixos = matplotlib.pyplot.subplots(nrows=1, ncols=1, figsize=(10, 10))\n",
    "\n",
    "tree.plot_tree(arvore_risco_credito, feature_names=previsores, class_names = arvore_risco_credito.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = ['história', 'dívida', 'garantias', 'renda']\n",
    "\n",
    "figura, eixos = matplotlib.pyplot.subplots(nrows=1, ncols=1, figsize=(10, 10))\n",
    "\n",
    "tree.plot_tree(arvore_risco_credito, feature_names=previsores, class_names = arvore_risco_credito.classes_, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = ['história', 'dívida', 'garantias', 'renda']\n",
    "\n",
    "figura, eixos = matplotlib.pyplot.subplots(nrows=1, ncols=1, figsize=(10, 10))\n",
    "\n",
    "tree.plot_tree(arvore_risco_credito, feature_names=previsores, class_names = arvore_risco_credito.classes_, filled=True); # o ; remove os textos redundantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# história boa, dívida alta, garantias nenhuma, renda > 35\n",
    "# história ruim, dívida alta, garantias adequada, renda < 15\n",
    "\n",
    "previsoes = arvore_risco_credito.predict([[0, 0, 1, 2], [2, 0, 0, 0]])\n",
    "previsoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base credit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('credit.pkl', 'rb') as f:\n",
    "    X_credit_treinamento, Y_credit_treinamento, X_credit_teste, Y_credit_teste = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arvore_credit = DecisionTreeClassifier(criterion='entropy', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arvore_credit.fit(X_credit_treinamento, Y_credit_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = arvore_credit.predict(X_credit_teste)\n",
    "previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_credit_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(Y_credit_teste, previsoes)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfusionMatrix(arvore_credit)\n",
    "cm.fit(X_credit_treinamento, Y_credit_treinamento)\n",
    "cm.score(X_credit_teste, Y_credit_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_credit_teste, previsoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arvore_credit.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(arvore_credit.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = ['income', 'age', 'loan']\n",
    "\n",
    "# Converta as classes para uma lista\n",
    "class_names_list = [str(classe) for classe in arvore_credit.classes_]\n",
    "\n",
    "fig, axes = matplotlib.pyplot.subplots(nrows=1, ncols=1, figsize=(20, 20))\n",
    "tree.plot_tree(arvore_credit, feature_names=previsores, class_names=class_names_list, filled=True)\n",
    "\n",
    "fig.savefig('arvore_credit.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = ['income', 'age', 'loan']\n",
    "\n",
    "fig, axes = matplotlib.pyplot.subplots(nrows=1, ncols=1, figsize=(20, 20))\n",
    "tree.plot_tree(arvore_credit, feature_names=previsores, class_names=['0', '1'], filled=True)\n",
    "\n",
    "fig.savefig('arvore_credit.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('census.pkl', 'rb') as f:\n",
    "    X_census_treinamento, Y_census_treinamento, X_census_teste, Y_census_teste = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arvore_census = DecisionTreeClassifier(criterion='entropy', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arvore_census.fit(X_census_treinamento, Y_census_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = arvore_census.predict(X_census_teste)\n",
    "previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_census_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia = accuracy_score(Y_census_teste, previsoes)\n",
    "acuracia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfusionMatrix(arvore_census)\n",
    "cm.fit(X_census_treinamento, Y_census_treinamento)\n",
    "cm.score(X_census_teste, Y_census_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_census_teste, previsoes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest (floresta randômica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Esolhe de forma aleatória `K` atributos para comparação da métrica de `pureza/impureza` (impureza de gini/entropia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Ensemble Learning** (Aprendizagem em Conjunto)\n",
    "\n",
    "    * Vários algoritmos juntos para construir um algoritmo mais `forte`\n",
    "\n",
    "    * Usa `média (regressão)` ou `votos da maioria (classificação)` para dar a resposta final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base crédito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_credit = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state=0)\n",
    "random_forest_credit.fit(X_credit_treinamento, Y_credit_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = random_forest_credit.predict(X_credit_teste)\n",
    "previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia = accuracy_score(Y_credit_teste, previsoes)\n",
    "acuracia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfusionMatrix(random_forest_credit)\n",
    "cm.fit(X_credit_treinamento, Y_credit_treinamento)\n",
    "cm.score(X_credit_teste, Y_credit_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_credit_teste, previsoes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_census = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_census.fit(X_census_treinamento, Y_census_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsao = random_forest_census.predict(X_census_teste)\n",
    "previsao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia =  accuracy_score(Y_census_teste, previsao)\n",
    "acuracia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfusionMatrix(random_forest_census)\n",
    "\n",
    "cm.fit(X_census_treinamento, Y_credit_treinamento)\n",
    "\n",
    "cm.score(X_census_teste, Y_census_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_census_teste, previsao))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizagem por Regras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo OneR (R = rules (regras))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ele se concentra em encontrar uma única regra de decisão baseada em uma única variável, escolhendo a variável que melhor discrimina as classes alvo.\n",
    "\n",
    "- Geralmente, o OneR utiliza a frequência de ocorrência de valores em uma variável em relação às classes de destino para criar uma regra simples que maximize a precisão na classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo PRISM (PRactical Incremental learning System)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- O PRISM é um sistema de aprendizado incremental projetado para construir e atualizar modelos de decisão com eficiência à medida que novos exemplos de dados estão disponíveis.\n",
    "\n",
    "- Ele é particularmente útil em situações em que o conjunto de dados cresce ao longo do tempo, e é desejável atualizar o modelo de forma incremental, sem precisar reprocessar todo o conjunto de dados.\n",
    "\n",
    "- O PRISM incorpora técnicas de aprendizado incremental para manter e melhorar continuamente o modelo à medida que mais dados são incorporados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indução de regras - Base risco crédito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quando trabalhamos com o `pandas` usamos o formato de `data frame`\n",
    "\n",
    "- Quando usamos o `Orange` usamos o formato `table`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_risco_credito = Orange.data.Table('Bases de dados/risco_credito_regras.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_risco_credito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_risco_credito.domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn2 = Orange.classification.rules.CN2Learner()\n",
    "regras_risco_credito = cn2(base_risco_credito)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for regras in regras_risco_credito.rule_list:\n",
    "    print(regras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes =  regras_risco_credito([['boa', 'alta', 'nenhuma', 'acima_35'], ['ruim', 'alta', 'adequada', '0_15']])\n",
    "previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_risco_credito.domain.class_var.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in previsoes:\n",
    "    print(base_risco_credito.domain.class_var.values[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indução de regras - Base crédito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit = Orange.data.Table('Bases de dados/credit_data_regras.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit.domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dividida = Orange.evaluation.testing.sample(base_credit, n=0.25)\n",
    "base_dividida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_treinamento = base_dividida[1]\n",
    "base_teste = base_dividida[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(base_treinamento), len(base_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn2 = Orange.classification.rules.CN2Learner()\n",
    "regras_credit = cn2(base_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for regras in regras_credit.rule_list:\n",
    "    print(regras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsao = Orange.evaluation.testing.TestOnTestData(base_treinamento, base_teste, [lambda testdata: regras_credit])\n",
    "previsao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Orange.evaluation.CA(previsao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificador base (majority learner) - Base crédito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority = Orange.classification.MajorityLearner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = Orange.evaluation.testing.TestOnTrainingData(base_credit, [majority])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Orange.evaluation.CA(previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for registro in base_credit:\n",
    "    print(registro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(str(registro.get_class()) for registro in base_credit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificador base (majority learner) - Base censo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_census = Orange.data.Table('Bases de dados/census_regras.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_census.domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority = Orange.classification.MajorityLearner()\n",
    "previsoes = Orange.evaluation.testing.TestOnTrainingData(base_census, [majority])\n",
    "Orange.evaluation.CA(previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(str(registro.get_class()) for registro in base_census)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizagem baseada em Instâncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN (k-Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A ideia central do k-NN é classificar ou prever um ponto de dados com base nas classes dos pontos de dados vizinhos a ele no espaço de características.\n",
    "\n",
    "- **Classificação k-NN:**\n",
    "\n",
    "    * Para um novo ponto de dados que precisa ser classificado, o algoritmo identifica os k pontos de dados mais próximos a ele no espaço de características.\n",
    "\n",
    "    * A classe mais comum entre esses k vizinhos é atribuída ao novo ponto de dados.\n",
    "\n",
    "    * O valor de k é um parâmetro que precisa ser definido antes de aplicar o algoritmo.\n",
    "\n",
    "- **Regressão k-NN:**\n",
    "\n",
    "    * Para problemas de regressão, em vez de prever uma classe, o k-NN prevê um valor numérico com base na média ou mediana dos valores dos k vizinhos mais próximos.\n",
    "\n",
    "    * Por exemplo, se estivermos prevendo o preço de uma casa, poderíamos tirar a média dos preços das k casas mais próximas.\n",
    "\n",
    "- **Distância entre pontos:**\n",
    "\n",
    "    * A métrica de distância usada para encontrar os vizinhos mais próximos pode variar, mas a distância euclidiana é comumente usada.\n",
    "\n",
    "    * Outras métricas de distância, como a distância de Manhattan, podem ser aplicadas dependendo do contexto.\n",
    "\n",
    "- **Escolha do valor de k:**\n",
    "\n",
    "    * A escolha do valor de k é um aspecto crítico do algoritmo k-NN. Valores pequenos de k podem ser sensíveis a ruídos, enquanto valores grandes podem suavizar as fronteiras entre as classes.\n",
    "\n",
    "    * É comum usar técnicas como validação cruzada para encontrar o valor de k que oferece o melhor desempenho no conjunto de dados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A maioria dos métodos de aprendizagem constroem um modelo após o treinamento (os dados são descartados após a criação do modelo)\n",
    "\n",
    "- Métodos baseados em instâncias simplismente armazenam os exemplos de treinamento\n",
    "\n",
    "- A generalização/previsão é feita somente quando uma nova instância precisa ser classificada `(lazy (preguiçosa))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Cálculo da distância (DE)** (Distância Euclidiana)\n",
    "\n",
    "    $DE(x, y) = \\sqrt{\\displaystyle\\sum_{i}^{p} (x_i - y_i)^2}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- O kNN é um algoritmo simples e poderoso\n",
    "\n",
    "- Indicado quando o relacionamento entre as `características é complexo`\n",
    "\n",
    "- Valor de `k` é pequeno: dados com ruídos ou outliers podem prejudicar\n",
    "\n",
    "- Valor de `k` é grande: tendência a classificar a classe com mais elementos `(overfitting)` - valor default 3 ou 5\n",
    "\n",
    "- Lento para fazer as previsões\n",
    "\n",
    "- Outras instâncias:\n",
    "    * Coeficiente de Pearson \n",
    "    * Índice de Tanimoto\n",
    "    * City Block\n",
    "\n",
    "- Para o algoritmo kNN é crucial que seja feita uma padronização nos dados antes da aplicação do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN - Base crédito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_credit = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n",
    "knn_credit.fit(X_credit_treinamento, Y_credit_treinamento)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = knn_credit.predict(X_credit_teste)\n",
    "previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(Y_credit_teste, previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfusionMatrix(knn_credit)\n",
    "cm.fit(X_credit_treinamento, Y_credit_treinamento)\n",
    "cm.score(X_credit_teste, Y_credit_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_credit_teste, previsoes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN - Base censo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_census = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n",
    "knn_census.fit(X_census_treinamento, Y_census_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsao = knn_census.predict(X_census_teste)\n",
    "previsao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(Y_census_teste, previsao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfusionMatrix(knn_census)\n",
    "cm.fit(X_census_treinamento, Y_census_treinamento)\n",
    "cm.score(X_census_teste, Y_census_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_census_teste, previsao))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A regressão logística é um modelo estatístico utilizado para análise de dados de classificação binária. \n",
    "\n",
    "- Diferentemente da regressão linear, que é usada para prever valores contínuos, a regressão logística é projetada para prever a probabilidade de um evento ocorrer, geralmente resultando em uma classificação binária, como sim/não, 1/0, positivo/negativo, entre outras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A função logística é fundamental na regressão logística e é definida como:\n",
    "\n",
    "    $P(Y=1) = \\frac{1}{1 + e^{-(b_0 + b_1 \\cdot X_1 + b_2 \\cdot X_2 + \\ldots + b_n \\cdot X_n)}}$ \n",
    "\n",
    "    Onde:\n",
    "    \n",
    "    - $P (Y=1)$ é a probabilidade condicionar de Y ser igual a 1 dado um conjunto de preditores X\n",
    "\n",
    "    - $e$ é a base do logaritmo natural \n",
    "\n",
    "    - $b_0, b_1, b_2, ..., b_n$ são os coeficientes do modelo\n",
    "\n",
    "    - $X_1, X_2, ..., X_n$ são as varáveis independentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A equação acima modela a relação log-odds entre as variáveis independentes e a variável dependente binária. A função logística transforma essa relação log-odds em uma probabilidade entre 0 e 1.\n",
    "\n",
    "- O treinamento da regressão logística geralmente envolve a maximização da verossimilhança, ajustando os coeficientes de modo a maximizar a probabilidade de observar os dados de treinamento dada a distribuição assumida pelo modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
